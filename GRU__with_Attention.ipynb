{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnSmtWfZsZJx"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9ynHF4KsaJk"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    \"\"\"\n",
        "    Represents a language class used for word indexing and counting.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the language.\n",
        "\n",
        "    Attributes:\n",
        "        name (str): The name of the language.\n",
        "        word2index (dict): A dictionary mapping words to their corresponding indices.\n",
        "        word2count (dict): A dictionary mapping words to their count in the language.\n",
        "        index2word (dict): A dictionary mapping indices to their corresponding words.\n",
        "        n_words (int): The total number of unique words in the language.\n",
        "\n",
        "    Methods:\n",
        "        addSentence(sentence): Splits a sentence into words and adds each word to the language.\n",
        "        addWord(word): Adds a word to the language, updating its index and count if it's new.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}  # Dictionary to map words to indices\n",
        "        self.word2count = {}  # Dictionary to count the occurrences of each word\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}  # Mapping indices to words, initialized with SOS and EOS tokens\n",
        "        self.n_words = 2  # Count of unique words, initialized with SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        \"\"\"\n",
        "        Splits a sentence into words and adds each word to the language.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): The input sentence to be processed.\n",
        "        \"\"\"\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        \"\"\"\n",
        "        Adds a word to the language, updating its index and count if it's new.\n",
        "\n",
        "        Args:\n",
        "            word (str): The word to be added to the language.\n",
        "        \"\"\"\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxaSdKjIBU_F"
      },
      "source": [
        "## Turn string into ASCII"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVzPgyO8tSjD"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    \"\"\"\n",
        "    Converts a Unicode string to ASCII.\n",
        "\n",
        "    Args:\n",
        "        s (str): The Unicode string to be converted.\n",
        "\n",
        "    Returns:\n",
        "        str: The ASCII representation of the input Unicode string.\n",
        "    \"\"\"\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    \"\"\"\n",
        "    Lowercases, trims, and removes non-letter characters from a string.\n",
        "\n",
        "    Args:\n",
        "        s (str): The input string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        str: The normalized string.\n",
        "    \"\"\"\n",
        "    s = unicodeToAscii(s.lower().strip())  # Convert to ASCII, lowercase, and strip whitespace\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)  # Add space before punctuation marks\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)  # Remove non-letter characters\n",
        "    return s.strip()  # Trim leading and trailing spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG2CWgqUBPob"
      },
      "source": [
        "## Reading the languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgrpd4vftVWp"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    \"\"\"\n",
        "    Reads language data from a file and creates language instances.\n",
        "\n",
        "    Args:\n",
        "        lang1 (str): The name of the first language.\n",
        "        lang2 (str): The name of the second language.\n",
        "        reverse (bool, optional): If True, reverses the language pairs. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Lang, Lang, List[List[str]]]: A tuple containing two language instances\n",
        "        and a list of language pairs.\n",
        "    \"\"\"\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('/content/eng-fra.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jMwTiPEnR4e"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    \"\"\"\n",
        "    Determines whether a pair of sentences meets the maximum length constraint and starts with an English prefix.\n",
        "\n",
        "    Args:\n",
        "        p (Tuple[str, str]): A pair of sentences (source and target).\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the pair meets the criteria, False otherwise.\n",
        "    \"\"\"\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[0].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    \"\"\"\n",
        "    Filters pairs of sentences based on length and English prefixes.\n",
        "\n",
        "    Args:\n",
        "        pairs (List[Tuple[str, str]]): A list of sentence pairs (source and target).\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: Filtered list of sentence pairs.\n",
        "    \"\"\"\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcgfrlcYBKYr"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQNmsNRyt6K"
      },
      "source": [
        "# ENGLISH-FRENCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOmHd1uuqG2",
        "outputId": "ba50c44d-7e6d-419d-85f0-2e7fa043ddd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 2991\n",
            "fra 4601\n",
            "['he s been drinking beer', 'il a ete boire une biere']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    \"\"\"\n",
        "    Prepares the data for language translation by reading sentence pairs,\n",
        "    filtering them based on length and prefixes, counting words, and creating language instances.\n",
        "\n",
        "    Args:\n",
        "        lang1 (str): The language code of the source language.\n",
        "        lang2 (str): The language code of the target language.\n",
        "        reverse (bool, optional): Flag to reverse the order of language pairs. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Tuple: A tuple containing input and output language instances, and filtered sentence pairs.\n",
        "    \"\"\"\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra')\n",
        "\n",
        "# print(\"Input language word2index:\")\n",
        "# print(input_lang.word2index)\n",
        "\n",
        "# print(\"\\nOutput language word2index:\")\n",
        "# print(output_lang.word2index)\n",
        "\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8BVj40_wMrw"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2ZtzaMiBHcG"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFqurBnfusQU"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder RNN module for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): The size of the input vocabulary.\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "        dropout_p (float, optional): Dropout probability. Defaults to 0.1.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Forward pass of the Encoder RNN.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor of shape (batch_size, seq_len).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, hidden_size).\n",
        "            torch.Tensor: Hidden state tensor of shape (1, batch_size, hidden_size).\n",
        "        \"\"\"\n",
        "        # Embed input\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # Forward pass through GRU\n",
        "        output, hidden = self.gru(embedded)\n",
        "\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sq10RFrBFbF"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_x4FJ-QwQ2F"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder RNN module for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "        output_size (int): The size of the output vocabulary.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the Decoder RNN.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Tensor containing the output features from the encoder.\n",
        "            encoder_hidden (torch.Tensor): Tensor containing the hidden state of the encoder.\n",
        "            target_tensor (torch.Tensor, optional): Tensor containing the target sequence. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, output_size).\n",
        "            torch.Tensor: Hidden state tensor of shape (1, batch_size, hidden_size).\n",
        "            None: Placeholder for consistency in the training loop.\n",
        "        \"\"\"\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None  # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        \"\"\"\n",
        "        Forward step of the Decoder RNN.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Tensor containing the input sequence.\n",
        "            hidden (torch.Tensor): Tensor containing the hidden state.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, hidden_size).\n",
        "            torch.Tensor: Hidden state tensor of shape (1, batch_size, hidden_size).\n",
        "        \"\"\"\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dujGrTZjBC00"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftmT34XdwTkd"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Bahdanau Attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        \"\"\"\n",
        "        Forward pass of the Bahdanau Attention mechanism.\n",
        "\n",
        "        Args:\n",
        "            query (torch.Tensor): Query tensor.\n",
        "            keys (torch.Tensor): Keys tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Context tensor.\n",
        "            torch.Tensor: Attention weights.\n",
        "        \"\"\"\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder RNN with Bahdanau Attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "        output_size (int): The size of the output vocabulary.\n",
        "        dropout_p (float, optional): Dropout probability. Defaults to 0.1.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the AttnDecoderRNN.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Encoder outputs.\n",
        "            encoder_hidden (torch.Tensor): Encoder hidden state.\n",
        "            target_tensor (torch.Tensor, optional): Target tensor. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoder outputs.\n",
        "            torch.Tensor: Decoder hidden state.\n",
        "            torch.Tensor: Attention weights.\n",
        "        \"\"\"\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        Forward step of the AttnDecoderRNN.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor.\n",
        "            hidden (torch.Tensor): Hidden state tensor.\n",
        "            encoder_outputs (torch.Tensor): Encoder outputs tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor.\n",
        "            torch.Tensor: Hidden state tensor.\n",
        "            torch.Tensor: Attention weights tensor.\n",
        "        \"\"\"\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KFIbFLewaUf"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    \"\"\"\n",
        "    Convert a sentence to a list of its corresponding token indexes.\n",
        "\n",
        "    Args:\n",
        "        lang (Lang): Language object containing word-to-index mapping.\n",
        "        sentence (str): Input sentence.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: List of token indexes.\n",
        "    \"\"\"\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    \"\"\"\n",
        "    Convert a sentence to a tensor with token indexes and EOS token.\n",
        "\n",
        "    Args:\n",
        "        lang (Lang): Language object containing word-to-index mapping.\n",
        "        sentence (str): Input sentence.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Tensor of token indexes with EOS token.\n",
        "    \"\"\"\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    \"\"\"\n",
        "    Generate input and target tensors from a pair of sentences.\n",
        "\n",
        "    Args:\n",
        "        pair (tuple): Pair of input and target sentences.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Input and target tensors.\n",
        "    \"\"\"\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    \"\"\"\n",
        "    Generate a DataLoader for training data.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): Batch size for DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Input language, output language, and DataLoader.\n",
        "    \"\"\"\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra')\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder-Decoder Model Training"
      ],
      "metadata": {
        "id": "opuUbbRt1Gc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_psxX_OwdLT"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Train one epoch of the sequence-to-sequence model.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): DataLoader for training data.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        encoder_optimizer (torch.optim.Optimizer): Optimizer for the encoder.\n",
        "        decoder_optimizer (torch.optim.Optimizer): Optimizer for the decoder.\n",
        "        criterion (torch.nn.Module): Loss criterion.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss over the epoch.\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjFuVAI_wh6I"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    \"\"\"\n",
        "    Convert seconds to minutes and seconds.\n",
        "\n",
        "    Args:\n",
        "        s (float): Time in seconds.\n",
        "\n",
        "    Returns:\n",
        "        str: Time formatted as minutes and seconds.\n",
        "    \"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    \"\"\"\n",
        "    Calculate the elapsed time since a given time and estimate remaining time.\n",
        "\n",
        "    Args:\n",
        "        since (float): The start time.\n",
        "        percent (float): The completion percentage.\n",
        "\n",
        "    Returns:\n",
        "        str: Elapsed time and estimated remaining time.\n",
        "    \"\"\"\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmOeRcmbwk18"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    \"\"\"\n",
        "    Plot the given points and set major tick locators at regular intervals.\n",
        "\n",
        "    Args:\n",
        "        points (array_like): The data points to plot.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Define the tick locator to put ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "\n",
        "    # Plot the points\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaZxCT_KwgDn"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    \"\"\"\n",
        "    Train the encoder-decoder model for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        train_dataloader (DataLoader): DataLoader for the training dataset.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n_epochs (int): Number of epochs for training.\n",
        "        learning_rate (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
        "        print_every (int, optional): Frequency of printing training progress. Default is 100.\n",
        "        plot_every (int, optional): Frequency of plotting losses. Default is 100.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p98nwG-lwnXa"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on a single sentence.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        sentence (str): Input sentence to be translated.\n",
        "        input_lang (Lang): Input language object containing word-to-index and index-to-word mappings.\n",
        "        output_lang (Lang): Output language object containing word-to-index and index-to-word mappings.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Tensor]: A tuple containing the list of decoded words and the decoder attention.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)  # Convert input sentence to tensor\n",
        "\n",
        "        # Encode input sentence\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        # Decode using the encoder outputs and hidden state\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        # Get the index of the highest probability output token for each timestep\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:  # If end of sentence token, append '<EOS>' and break\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])  # Append the decoded word\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwq-ktxUw2RP"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on random input-output pairs.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n (int): Number of pairs to evaluate. Defaults to 10.\n",
        "    \"\"\"\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)  # Choose a random pair from the dataset\n",
        "        print('>', pair[0])  # Print the input sequence\n",
        "        print('=', pair[1])  # Print the target output sequence\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)  # Evaluate the pair\n",
        "        output_sentence = ' '.join(output_words)  # Convert the list of output words to a sentence\n",
        "        print('<', output_sentence)  # Print the generated output sequence\n",
        "        print('')  # Print an empty line for clarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-AXT6sbOT08"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on random input-output pairs.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n (int): Number of pairs to evaluate. Defaults to 10.\n",
        "    \"\"\"\n",
        "    total_correct = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)  # Choose a random pair from the dataset\n",
        "        print('>', pair[0])  # Print the input sequence\n",
        "        print('=', pair[1])  # Print the target output sequence\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)  # Evaluate the pair\n",
        "        output_sentence = ' '.join(output_words)  # Convert the list of output words to a sentence\n",
        "        print('<', output_sentence)  # Print the generated output sequence\n",
        "\n",
        "        # Calculate accuracy\n",
        "        target_words = pair[1].split()\n",
        "        correct = sum(1 for pred, target in zip(output_words, target_words) if pred == target)\n",
        "        total_correct += correct\n",
        "        total_words += len(target_words)\n",
        "\n",
        "        print('Accuracy for this pair:', correct / len(target_words))  # Print accuracy for this pair\n",
        "        print('')  # Print an empty line for clarity\n",
        "\n",
        "    print('Overall accuracy:', total_correct / total_words)  # Print overall accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHhtT2k43CzB"
      },
      "source": [
        "### Encoder-Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "ygyriRQRu5fX",
        "outputId": "707e511e-ca71-4f01-eaea-4dc8969d30dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 2991\n",
            "fra 4601\n",
            "3m 35s (- 10m 47s) (5 25%) 2.0447\n",
            "7m 3s (- 7m 3s) (10 50%) 1.1028\n",
            "10m 28s (- 3m 29s) (15 75%) 0.7320\n",
            "13m 54s (- 0m 0s) (20 100%) 0.5182\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 20, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIEI5_2iuUBb",
        "outputId": "3ea0583c-2e02-4857-8071-d882efc3703a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> i m looking forward to the return of spring\n",
            "= j attends avec impatience le retour du printemps\n",
            "< j attends avec impatience le programme du printemps <EOS>\n",
            "Accuracy for this pair: 0.875\n",
            "\n",
            "> we re here early\n",
            "= nous sommes la tot\n",
            "< nous sommes la tot avec mon ami <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> i m letting you go\n",
            "= je vous laisse partir\n",
            "< je te suis tellement reconnaissant pour votre aide <EOS>\n",
            "Accuracy for this pair: 0.25\n",
            "\n",
            "> they re in the shower\n",
            "= ils sont dans la douche\n",
            "< elles sont dans le laboratoire de sciences <EOS>\n",
            "Accuracy for this pair: 0.4\n",
            "\n",
            "> he is watching my every move\n",
            "= il observe mon moindre mouvement\n",
            "< il a etre la tete qui tourne <EOS>\n",
            "Accuracy for this pair: 0.2\n",
            "\n",
            "> you re in the right place\n",
            "= tu es au bon endroit\n",
            "< tu es responsable de ce que j ai <EOS>\n",
            "Accuracy for this pair: 0.4\n",
            "\n",
            "> you re very open\n",
            "= vous etes tres ouvert\n",
            "< vous etes tres religieuse ces droit a voyager <EOS>\n",
            "Accuracy for this pair: 0.75\n",
            "\n",
            "> you re not alone anymore\n",
            "= vous n etes plus seule\n",
            "< vous n etes plus seule n est ce pas ?\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> i m tough\n",
            "= je suis dure\n",
            "< je suis interesse par la ceramique orientale <EOS>\n",
            "Accuracy for this pair: 0.6666666666666666\n",
            "\n",
            "> i am from shizuoka\n",
            "= je suis de shizuoka\n",
            "< je suis responsable de l argent a la maison <EOS>\n",
            "Accuracy for this pair: 0.5\n",
            "\n",
            "Overall accuracy: 0.6170212765957447\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SjoX3WlHnaS",
        "outputId": "39106b20-3a7b-4f8f-f6bf-5297ed40b382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Accuracy without Attention: 0.8981\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    \"\"\"\n",
        "    Function to calculate accuracy.\n",
        "    \"\"\"\n",
        "    return np.mean(np.array(predictions) == np.array(targets))\n",
        "\n",
        "def evaluate_accuracy(encoder, decoder, dataloader, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Function to evaluate accuracy on a dataset.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            input_tensor, target_tensor = data\n",
        "\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            _, topi = decoder_outputs.topk(1)\n",
        "            decoded_ids = topi.squeeze()\n",
        "\n",
        "            for idx_tensor, target_tensor in zip(decoded_ids, target_tensor.squeeze()):\n",
        "                for idx in idx_tensor:\n",
        "                    idx = idx.item()  # Convert tensor element to scalar\n",
        "                    if idx == EOS_token:\n",
        "                        predictions.append('<EOS>')\n",
        "                    else:\n",
        "                        predictions.append(output_lang.index2word[idx])\n",
        "\n",
        "\n",
        "                for target_idx in target_tensor:\n",
        "                    target = target_idx.item()  # Convert tensor element to scalar\n",
        "                    if target == EOS_token:\n",
        "                        targets.append('<EOS>')\n",
        "                    else:\n",
        "                        targets.append(output_lang.index2word[target])\n",
        "\n",
        "    return calculate_accuracy(predictions, targets)\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        for idx, target_idx in zip(decoded_ids, target_tensor.squeeze()):\n",
        "            if idx.item() == EOS_token:\n",
        "                predictions.append('<EOS>')\n",
        "            else:\n",
        "                predictions.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "            if target_idx.item() == EOS_token:\n",
        "                targets.append('<EOS>')\n",
        "            else:\n",
        "                targets.append(output_lang.index2word[target_idx.item()])\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = calculate_accuracy(predictions, targets)\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "            print(\"Training Accuracy: %.4f\" % accuracy)\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "# Evaluate training accuracy\n",
        "train_accuracy = evaluate_accuracy(encoder, decoder, train_dataloader, input_lang, output_lang)\n",
        "print(\"Final Training Accuracy without Attention: %.4f\" % train_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzdldkU03HVC"
      },
      "source": [
        "### Attention Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZs608LpsCF5"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Train one epoch of the sequence-to-sequence model.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): DataLoader for training data.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        encoder_optimizer (torch.optim.Optimizer): Optimizer for the encoder.\n",
        "        decoder_optimizer (torch.optim.Optimizer): Optimizer for the decoder.\n",
        "        criterion (torch.nn.Module): Loss criterion.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss over the epoch.\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiHWwDlNsP2A"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    \"\"\"\n",
        "    Convert seconds to minutes and seconds.\n",
        "\n",
        "    Args:\n",
        "        s (float): Time in seconds.\n",
        "\n",
        "    Returns:\n",
        "        str: Time formatted as minutes and seconds.\n",
        "    \"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    \"\"\"\n",
        "    Calculate the elapsed time since a given time and estimate remaining time.\n",
        "\n",
        "    Args:\n",
        "        since (float): The start time.\n",
        "        percent (float): The completion percentage.\n",
        "\n",
        "    Returns:\n",
        "        str: Elapsed time and estimated remaining time.\n",
        "    \"\"\"\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eSZB5lusV1B"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    \"\"\"\n",
        "    Plot the given points and set major tick locators at regular intervals.\n",
        "\n",
        "    Args:\n",
        "        points (array_like): The data points to plot.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Define the tick locator to put ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "\n",
        "    # Plot the points\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w35Lu8tsc94"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    \"\"\"\n",
        "    Train the encoder-decoder model for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        train_dataloader (DataLoader): DataLoader for the training dataset.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n_epochs (int): Number of epochs for training.\n",
        "        learning_rate (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
        "        print_every (int, optional): Frequency of printing training progress. Default is 100.\n",
        "        plot_every (int, optional): Frequency of plotting losses. Default is 100.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLDJKvJmsk3d"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on a single sentence.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        sentence (str): Input sentence to be translated.\n",
        "        input_lang (Lang): Input language object containing word-to-index and index-to-word mappings.\n",
        "        output_lang (Lang): Output language object containing word-to-index and index-to-word mappings.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Tensor]: A tuple containing the list of decoded words and the decoder attention.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)  # Convert input sentence to tensor\n",
        "\n",
        "        # Encode input sentence\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        # Decode using the encoder outputs and hidden state\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        # Get the index of the highest probability output token for each timestep\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:  # If end of sentence token, append '<EOS>' and break\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])  # Append the decoded word\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHCUMJtqmJ74"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on random input-output pairs.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n (int): Number of pairs to evaluate. Defaults to 10.\n",
        "    \"\"\"\n",
        "    total_correct = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)  # Choose a random pair from the dataset\n",
        "        print('>', pair[0])  # Print the input sequence\n",
        "        print('=', pair[1])  # Print the target output sequence\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)  # Evaluate the pair\n",
        "        output_sentence = ' '.join(output_words)  # Convert the list of output words to a sentence\n",
        "        print('<', output_sentence)  # Print the generated output sequence\n",
        "\n",
        "        # Calculate accuracy\n",
        "        target_words = pair[1].split()\n",
        "        correct = sum(1 for pred, target in zip(output_words, target_words) if pred == target)\n",
        "        total_correct += correct\n",
        "        total_words += len(target_words)\n",
        "\n",
        "        print('Accuracy for this pair:', correct / len(target_words))  # Print accuracy for this pair\n",
        "        print('')  # Print an empty line for clarity\n",
        "\n",
        "    print('Overall accuracy:', total_correct / total_words)  # Print overall accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Model"
      ],
      "metadata": {
        "id": "C2mDj1gq1Myf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "bA2nvXuNws-Q",
        "outputId": "6c442408-720a-45dd-d2a7-db8885a3a34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 2991\n",
            "fra 4601\n",
            "4m 26s (- 13m 19s) (5 25%) 1.8641\n",
            "8m 45s (- 8m 45s) (10 50%) 0.8642\n",
            "12m 57s (- 4m 19s) (15 75%) 0.4940\n",
            "17m 11s (- 0m 0s) (20 100%) 0.3204\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABA10lEQVR4nO3deVxU5eIG8OfMwAygzCD74iiLgjvgAqKWWrhfbrao1f1lt+WWXS2VSuVWelspc+sW1W313tvmktqiaeZGGmYugyuogIKyKCAzrAPMnN8f2BQpyiDDmeX5fj7nD8f3OM+czzTzdM475xVEURRBREREJBGZ1AGIiIjIubGMEBERkaRYRoiIiEhSLCNEREQkKZYRIiIikhTLCBEREUmKZYSIiIgkxTJCREREknKROkBrmEwmFBYWwtPTE4IgSB2HiIiIWkEURVRWViI4OBgyWcvnP+yijBQWFkKj0Ugdg4iIiNqgoKAAXbt2bfHv7aKMeHp6Amh6MSqVSuI0RERE1Bp6vR4ajcb8Pd4Suygjv16aUalULCNERER25npTLDiBlYiIiCTFMkJERESSYhkhIiIiSbGMEBERkaRYRoiIiEhSLCNEREQkKZYRIiIikhTLCBEREUmKZYSIiIgkxTJCREREkmIZISIiIkmxjBAREZGknLqMHD2vw73v70V5db3UUYiIiJyW05YRURQxb+1h/JRThmfWH4EoilJHIiIickpOW0YEQcDiuwbAVS7gu6PFWH/ovNSRiIiInJLTlhEA6BeixpzESADAoq+O4XxFrcSJiIiInI9TlxEAePTmcAzs5oVKQyOeWp0Jk4mXa4iIiDqS05cRF7kMy6bGwN1VjozcMqz86YzUkYiIiJyK05cRAAj17YRnJvUGALy2OQunL1RKnIiIiMh5sIxc9pf4bhgV5QdDowlzV2WiwWiSOhIREZFTYBm5TBAELL5zALw8XHHkvA5vbjsldSQiIiKnwDLyO/4qN7w8uT8AIG1nDg7lX5I4ERERkeNjGfmDSQOCcFtMMIwmEcmrM1Fbb5Q6EhERkUOzuIykp6cjKSkJwcHBEAQBGzZsuO4+n376KaKjo+Hh4YGgoCA8+OCDKCsra0veDvHCn/shUOWGvNJqpH53Quo4REREDs3iMlJdXY3o6GikpaW1avyePXswffp0PPTQQzh27BjWrFmDffv24W9/+5vFYTuK2sMVS6ZEAwD+m3EW6ScvSpyIiIjIcVlcRiZMmICXXnoJt99+e6vGZ2RkIDQ0FE888QTCwsIwYsQIPProo9i3b5/FYTvSiJ6++OuwUADA02szUVHDxfSIiIiswepzRhISElBQUIBNmzZBFEWUlJRg7dq1mDhxYov7GAwG6PX6ZpsU5o/vhXC/TijRG/DcV8ckyUBEROTorF5Ghg8fjk8//RTTpk2DQqFAYGAg1Gr1NS/zpKamQq1WmzeNRmPtmFflrpBj+dQYyGUCvsksxNeZhZLkICIicmRWLyPHjx/H7NmzsXDhQhw4cACbN2/GmTNnMGPGjBb3SUlJgU6nM28FBQXWjtmiaI0XZo3uAQB4bsNRFOvqJMtCRETkiARRFNu8MpwgCFi/fj0mT57c4pj77rsPdXV1WLNmjfmx3bt346abbkJhYSGCgoKu+zx6vR5qtRo6nQ4qlaqtcduswWjCne/8hMPndLg50g//eWAIBEHo8BxERET2pLXf31Y/M1JTUwOZrPnTyOVyAMAN9KAO5Xp5MT2liwzpJy/ik71npY5ERETkMCwuI1VVVdBqtdBqtQCAvLw8aLVa5OfnA2i6xDJ9+nTz+KSkJKxbtw7vvPMOcnNzsWfPHjzxxBOIi4tDcHBw+7yKDtDDvzMWTOgFAHh50wnkXqySOBEREZFjsLiM7N+/H7GxsYiNjQUAJCcnIzY2FgsXLgQAFBUVmYsJAPz1r3/FsmXL8NZbb6Ffv36YMmUKoqKisG7dunZ6CR3n/oRQDO/hg7oGE5JXZ6KRi+kRERHdsBuaM9JRpJ4z8nuFFbUYtyIdlXWNeHJMJB6/taekeYiIiGyVzcwZcTTBXu548bZ+AIA3tp3CkXM6iRMRERHZN5aRNrgtJhiT+geh0SRi7mot6hq4mB4REVFbsYy0gSAIeGlyP/h5KnH6QhUWb86WOhIREZHdYhlpoy6dFFh81wAAwEd78vBTTqnEiYiIiOwTy8gNGB3lj3vjuwEAnlqdCX1dg8SJiIiI7A/LyA16ZmJvdPfxQKGuDv/8movpERERWYpl5AZ1Urpg2dRoyARg3cHz2Hy0SOpIREREdoVlpB0M6u6NGSMjAAAp647gQiUX0yMiImotlpF2MicxEn2CVLhU04CUL4/Yzbo7REREUmMZaScKFxmWT4uBQi7DtqwLWPVLgdSRiIiI7ALLSDuKCvTE0+OiAAAvfnsc+WU1EiciIiKyfSwj7eyhEWGID/NGdb0Ryau1MJp4uYaIiOhaWEbamUwmYMmUaHRWumD/2Ut4Lz1X6khEREQ2jWXECjTeHliY1AcAsGxrNk4U6SVOREREZLtYRqxkyqCuGNMnAA1GEXNXaWFo5GJ6REREV8MyYiWCICD1jv7w7axAVnEllm09KXUkIiIim8QyYkW+nZV45fb+AID30nOxL69c4kRERES2h2XEysb2DcSUQV0hisCTa7SoMjRKHYmIiMimsIx0gIVJfdC1izsKymvx0rfHpY5DRERkU1hGOoCnmyuWTomGIABf/FKAH46XSB2JiIjIZrCMdJD4cB/87aZwAMCCdYdRVmWQOBEREZFtYBnpQMljIhEV4InSqnr8Yz0X0yMiIgJYRjqUm6scy6ZFw1UuYMuxEnx58LzUkYiIiCTHMtLB+garMScxEgDw/NfHcO4SF9MjIiLnxjIigRkjIzCoexdUGhrx9JrDMHExPSIicmIsIxKQywQsmxoND4UcGbll+GhPntSRiIiIJMMyIpHuPp3wzKTeAIDFW7JxsqRS4kRERETSYBmR0L1x3TA6yg/1jSbMXaVFfaNJ6khEREQdjmVEQoIg4LU7B6CLhyuOFerx5vZTUkciIiLqcCwjEvNXueHly4vppe04jYP5lyRORERE1LFYRmzAxP5BuD02BCYRSF6lRU09F9MjIiLnwTJiI/75574IUrvhTFkNXtl0Quo4REREHYZlxEao3V2xZEo0AOCTvfnYmX1B4kREREQdw+Iykp6ejqSkJAQHB0MQBGzYsOG6+xgMBjzzzDPo3r07lEolQkND8dFHH7Ulr0Mb3sMXfx0WCgCYt/YwKmrqpQ1ERETUASwuI9XV1YiOjkZaWlqr95k6dSq2bduGDz/8ENnZ2fj8888RFRVl6VM7hQUTeiHCrxMuVBrw7IajUschIiKyOhdLd5gwYQImTJjQ6vGbN2/Grl27kJubC29vbwBAaGiopU/rNNxc5Vg+LQa3v/0Tvj1chDF9zuO2mBCpYxEREVmN1eeMfP311xg8eDAWL16MkJAQREZG4qmnnkJtbW2L+xgMBuj1+mabMxnQ1QuP39IDAPDchqMo0rV8rIiIiOyd1ctIbm4udu/ejaNHj2L9+vVYsWIF1q5di7///e8t7pOamgq1Wm3eNBqNtWPanJmjeyC6qxr6ukbMW8vF9IiIyHFZvYyYTCYIgoBPP/0UcXFxmDhxIpYtW4b//Oc/LZ4dSUlJgU6nM28FBQXWjmlzXOUyLJsWAzdXGX48VYpPfj4rdSQiIiKrsHoZCQoKQkhICNRqtfmx3r17QxRFnDt37qr7KJVKqFSqZpszivDrjJQJTYvpvbLpBHIuVkmciIiIqP1ZvYwMHz4chYWFqKr67Yv05MmTkMlk6Nq1q7Wf3u7dN7Q7burpi7oGE5JXZ6LRyMX0iIjIsVhcRqqqqqDVaqHVagEAeXl50Gq1yM/PB9B0iWX69Onm8ffeey98fHzwwAMP4Pjx40hPT8fTTz+NBx98EO7u7u3zKhyYTCZg8V0DoHJzQWZBBdJ25EgdiYiIqF1ZXEb279+P2NhYxMbGAgCSk5MRGxuLhQsXAgCKiorMxQQAOnfujK1bt6KiogKDBw/GX/7yFyQlJeFf//pXO70ExxekdseLk/sBAP61/RQOn6uQNhAREVE7EkRRtPmfaej1eqjVauh0OqedPyKKImZ9fggbDxchwq8TNj5xE9xc5VLHIiIialFrv7+5No2dEAQBL93WD/6eSuRcrMZrm7OkjkRERNQuWEbsSJdOCrx21wAAwMd7zmDP6VKJExEREd04lhE7MzrKH3+J7wYAeGpNJnS1DRInIiIiujEsI3bomUm9EerjgSJdHf759TGp4xAREd0QlhE75KFwwbJpMZAJwPpD57HpSJHUkYiIiNqMZcRODezWBX8f1bSY3jPrj+CCvk7iRERERG3DMmLHnri1J/oGq3CppgHzvzwMO/iVNhER0RVYRuyYwkWG5dNioHCRYUf2RXy+z/kWFCQiIvvHMmLnIgM8MW9cFADgpY3HcbasWuJERERElmEZcQAPDg/D0HBv1NQb8eTqTBhNvFxDRET2g2XEAchkApZMiUZnpQv2n72Ef6dzMT0iIrIfLCMOomsXDyxK6gMAWL71JI4V6iRORERE1DosIw7krkFdMbZPABqMIpJXZaKuwSh1JCIioutiGXEggiAg9Y7+8O2sQHZJJZZvPSl1JCIioutiGXEwPp2VePWOpsX03vsxFz/nlkmciIiI6NpYRhxQYp8ATBusgSgCT67JRGUdF9MjIiLbxTLioJ79U2907eKOc5dq8eK3x6WOQ0RE1CKWEQfl6eaKZVNjIAjA6v3n8P2xYqkjERERXRXLiAOLC/PGIzeFAwBS1h1BaZVB4kRERERXYhlxcMljI9Er0BNl1fX4x7ojXEyPiIhsDsuIg1O6yLFsagxc5QK+P16CtQfOSR2JiIioGZYRJ9AnWIW5YyIBAM9/cxwF5TUSJyIiIvoNy4iTePTmCAzu3gVVhkY8tSYTJi6mR0RENoJlxEnIZQKWTo2Gh0KOn/PK8dGePKkjERERAWAZcSrdfTrhuT81Laa3eEs2TpZUSpyIiIiIZcTp3D1Eg1t6+aO+0YQ5X2hR32iSOhIRETk5lhEnIwgCXr2zP7p4uOJ4kR5vbONiekREJC2WESfk7+mGV27vDwB4Z2cODpwtlzgRERE5M5YRJzWhfxDuiA2BSQSSV2ei2tAodSQiInJSLCNObNGf+yJY7YazZTV4ZdMJqeMQEZGTYhlxYmp3V7w+JRoA8OnP+diRfUHiRERE5IxYRpzc8B6+eGB4KABg3trDuFRdL20gIiJyOhaXkfT0dCQlJSE4OBiCIGDDhg2t3nfPnj1wcXFBTEyMpU9LVjR/fC/08O+Mi5UGPLvhKBfTIyKiDmVxGamurkZ0dDTS0tIs2q+iogLTp0/HrbfeaulTkpW5ucqxfGoMXGQCNh4pwteZhVJHIiIiJ2JxGZkwYQJeeukl3H777RbtN2PGDNx7771ISEiw9CmpA/TvqsYTt/YEADy34SiKdLUSJyIiImfRIXNGPv74Y+Tm5mLRokWtGm8wGKDX65ttZH1/HxWBaI0X9HWNeHrNYS6mR0REHcLqZeTUqVNYsGABPvnkE7i4uLRqn9TUVKjVavOm0WisnJIAwEUuw/Kp0XBzlWH36VL8N+OM1JGIiMgJWLWMGI1G3HvvvXj++ecRGRnZ6v1SUlKg0+nMW0FBgRVT0u+F+3XGPyb2BgCkfpeF0xeqJE5ERESOzqplpLKyEvv378esWbPg4uICFxcXvPDCC8jMzISLiwu2b99+1f2USiVUKlWzjTrOfUO746aevjA0mpC8WosGIxfTIyIi67FqGVGpVDhy5Ai0Wq15mzFjBqKioqDVahEfH2/Np6c2EgQBr98VDZWbCw6f0yFtx2mpIxERkQNr3SSO36mqqsLp0799OeXl5UGr1cLb2xvdunVDSkoKzp8/j//+97+QyWTo169fs/39/f3h5uZ2xeNkWwLVbnhxcj/M/kKLN7efxugof0RrvKSORUREDsjiMyP79+9HbGwsYmNjAQDJycmIjY3FwoULAQBFRUXIz89v35QkidtiQvCnAUEwmkTMXa1Fbb1R6khEROSABNEObrep1+uhVquh0+k4f6SDVdTUY9yKdJToDfjrsFD88899pY5ERER2orXf31ybhq7Jy0OBxXc1Laa38qcz2H2qVOJERETkaFhG6LpGRvrhvqHdAQBPr82ErrZB4kRERORIWEaoVVIm9kKYbycU6eqw6KujUschIiIHwjJCreKhcMHSqdGQCcAGbSE2Hi6SOhIRETkIlhFqtYHdumDm6B4AgGc2HMEFfZ3EiYiIyBGwjJBFHr+lJ/qFqFBR04B5Xx6GHfwYi4iIbBzLCFlE4SLD8qkxULjIsDP7Ij7bx3vKEBHRjWEZIYv1DPDEvHFRAICXvj2BM6XVEiciIiJ7xjJCbfLg8DAkhPugtsGI5NVaNHIxPSIiaiOWEWoTmUzAkqnR8FS64GB+Bf6dnit1JCIislMsI9RmIV7u5tvDL996EkfP6yRORERE9ohlhG7IHQNDMK5vABpNIpJXa1HXwMX0iIjIMiwjdEMEQcArt/eHb2clTpZUYen32VJHIiIiO8MyQjfMp7MSr93ZHwDwwe487M0tkzgRERHZE5YRahe39g7A3UM0EEXgydWZqKzjYnpERNQ6LCPUbp79Ux9ovN1xvqIWL3xzXOo4RERkJ1hGqN10Vrpg6ZQYCAKw5sA5fH+sWOpIRERkB1hGqF3FhXnjkZvDAQAp646gtMogcSIiIrJ1LCPU7pLHRKJXoCfKquux4MsjXEyPiIiuiWWE2p3SRY7l02KgkMvww4kSrNl/TupIRERkw1hGyCp6B6mQPDYSAPD8N8dQUF4jcSIiIrJVLCNkNX+7KRxDQrugut6IJ9dkwmji5RoiIroSywhZjVwmYOmUGHRSyLEvrxwf7uZiekREdCWWEbKqbj4eeO5PfQAAS7acRFaxXuJERERka1hGyOqmDdEgsbc/6o0mzF2VCUMjF9MjIqLfsIyQ1QmCgNQ7BsC7kwInivR444dTUkciIiIbwjJCHcLPU4lXbu8HAHh3Vw4OnC2XOBEREdkKlhHqMOP7BeGOgSEwicDcVZmoNjRKHYmIiGwAywh1qH/+uS9CvNyRX16DlzaekDoOERHZAJYR6lAqN1e8PmUAAODzffnYnlUicSIiIpIaywh1uGERvnhweBgAYN7aIyivrpc4ERERSYllhCQxb3wUevh3RmmVAc9u4GJ6RETOjGWEJOHmKseKaTFwkQnYdKQYG7TnpY5EREQSsbiMpKenIykpCcHBwRAEARs2bLjm+HXr1mHMmDHw8/ODSqVCQkICtmzZ0ta85ED6hagx+9aeAICFXx1DYUWtxImIiEgKFpeR6upqREdHIy0trVXj09PTMWbMGGzatAkHDhzA6NGjkZSUhEOHDlkclhzPY6MiEKPxQmVdI55akwkTF9MjInI6gngDF+sFQcD69esxefJki/br27cvpk2bhoULF7ZqvF6vh1qthk6ng0qlakNSsmW5F6sw8V8/oq7BhEVJffDA5cmtRERk31r7/d3hc0ZMJhMqKyvh7e3d4hiDwQC9Xt9sI8cV7tcZz0zsDQB49bssnL5QKXEiIiLqSB1eRpYsWYKqqipMnTq1xTGpqalQq9XmTaPRdGBCksL/De2OmyP9YGhsWkyvwWiSOhIREXWQDi0jn332GZ5//nmsXr0a/v7+LY5LSUmBTqczbwUFBR2YkqQgCAJev2sA1O6uOHJehze3n5Y6EhERdZAOKyNffPEFHn74YaxevRqJiYnXHKtUKqFSqZpt5PgCVG54aXLTYnppO05DW1AhbSAiIuoQHVJGPv/8czzwwAP4/PPPMWnSpI54SrJTSdHBSIoOhtEkInmVFrX1RqkjERGRlVlcRqqqqqDVaqHVagEAeXl50Gq1yM/PB9B0iWX69Onm8Z999hmmT5+OpUuXIj4+HsXFxSguLoZOp2ufV0AO58Xb+iJApURuaTVe/Y6L6REROTqLy8j+/fsRGxuL2NhYAEBycjJiY2PNP9MtKioyFxMAeO+999DY2IiZM2ciKCjIvM2ePbudXgI5Gi8PBV6/KxoA8J+Ms/jx1EWJExERkTXd0H1GOgrvM+KcFn51FP/NOItAlRu2zLkZag9XqSMREZEFbPY+I0StlTKhN8J9O6FYX4fnvjoqdRwiIrISlhGyWe4KOZZOjYZcJuDrzEJ8k1kodSQiIrIClhGyabHdumDmqAgAwLMbjqJEXydxIiIiam8sI2TzHr+1J/qHqKGrbcDTaw/DDqY5ERGRBVhGyOa5ymVYPi0aShcZ0k9exCc/519/JyIishssI2QXevh7Yv74XgCAVzaeQF5ptcSJiIiovbCMkN3467BQDIvwQW2DEcmrtWjkYnpERA6BZYTshkwm4PUp0fBUuuBQfgXe3ZUjdSQiImoHLCNkV0K83PH8bX0BACt+OIWj57msABGRvWMZIbtze2wIJvQLRKNJxNxVWtQ1cDE9IiJ7xjJCdkcQBLx8e3/4dlbi1IUqLNmSLXUkIiK6ASwjZJe8Oymw+K7+AIAP9+QhI6dM4kRERNRWLCNkt27pFYB74jQQReCpNZnQ1zVIHYmIiNqAZYTs2rOT+qCbtwfOV9Ti+a+PSx2HiIjagGWE7FonpQuWTY2GIABfHjyHzUeLpY5EREQWYhkhuzc41BuP3ty0mN4/1h/BxUqDxImIiMgSLCPkEOaO6YlegZ4or65HyjoupkdEZE9YRsghKF3kWHF3DBRyGX44cQGr9xdIHYmIiFqJZYQcRq9AFZ4cGwkAeOGb48gvq5E4ERERtQbLCDmUh28KR1yoN6rrjXhyjRZGEy/XEBHZOpYRcihymYClU6PRSSHHL2cu4YMfc6WORERE18EyQg5H4+2BhUl9AABLvz+JE0V6iRMREdG1sIyQQ5o6WIPE3v6oN5owd5UWhkYupkdEZKtYRsghCYKA1DsGwKeTAlnFlVi+9ZTUkYiIqAUsI+Sw/DyVePn2psX0/p2eg1/OlEuciIiIroZlhBza+H6BuHNgV4gikLxaiypDo9SRiIjoD1hGyOEt+nMfhHi5o6C8Fi9v5GJ6RES2hmWEHJ7KzRVLpjQtpvf5vgJsO1EidSQiIvodlhFyCgkRPnhoeBgAYP6XR1BWxcX0iIhsBcsIOY2nxkWhp39nlFYZ8Mz6o1xMj4jIRrCMkNNwc5Vj+bQYuMgEbD5WjPWHzksdiYiIwDJCTqZfiBpzEnsCABZ9dQznK2olTkRERBaXkfT0dCQlJSE4OBiCIGDDhg3X3Wfnzp0YOHAglEolevTogZUrV7YhKlH7mDEyArHdvFBpaMRTqzNh4mJ6RESSsriMVFdXIzo6Gmlpaa0an5eXh0mTJmH06NHQarWYM2cOHn74YWzZssXisETtwUUuw7KpMXB3lSMjtwwf/3RG6khERE5NEG9gFp8gCFi/fj0mT57c4pj58+dj48aNOHr0qPmxu+++GxUVFdi8eXOrnkev10OtVkOn00GlUrU1LlEz/9t7Fs9tOAqFiwwbHx+BngGeUkciInIorf3+tvqckYyMDCQmJjZ7bNy4ccjIyLD2UxNd0//Fd8PISD/UN5owd7UWDUaT1JGIiJyS1ctIcXExAgICmj0WEBAAvV6P2tqrTx40GAzQ6/XNNqL2JggCFt81AF4erjh6Xo83t3ExPSIiKdjkr2lSU1OhVqvNm0ajkToSOagAlRtemtwPAJC2MweH8i9JnIiIyPlYvYwEBgaipKT57bdLSkqgUqng7u5+1X1SUlKg0+nMW0FBgbVjkhP704Bg3BYTDKNJRPLqTNTUczE9IqKOZPUykpCQgG3btjV7bOvWrUhISGhxH6VSCZVK1WwjsqYX/twPgSo35JVWI3VTltRxiIicisVlpKqqClqtFlqtFkDTT3e1Wi3y8/MBNJ3VmD59unn8jBkzkJubi3nz5iErKwtvv/02Vq9ejblz57bPKyBqB2oPV7w+ZQCApl/Z7Dp5UeJERETOw+Iysn//fsTGxiI2NhYAkJycjNjYWCxcuBAAUFRUZC4mABAWFoaNGzdi69atiI6OxtKlS/HBBx9g3Lhx7fQSiNrHTT39cH9CdwDAvLWZqKiplzgREZFzuKH7jHQU3meEOkptvRGT3vwRuRerkRQdjDfviZU6EhGR3bKZ+4wQ2RN3hRzLpsZALhPwTWYhvs4slDoSEZHDYxkh+oMYjRdmju4BAHh2/REU6+okTkRE5NhYRoiu4vFbemBAVzX0dY14em0m7OBqJhGR3WIZIboK18uL6SldZPjxVCk+2XtW6khERA6LZYSoBT38O2PBhF4AgJc3nUDuxSqJExEROSaWEaJruD8hFMN7+KCuwYS5qzPRyMX0iIjaHcsI0TXIZAJevysanm4uyCyowNs7c6SORETkcFhGiK4j2MsdL9zWFwDwr22ncOScTuJERESOhWWEqBUmx4RgYv9ANJpEzF2tRV2DUepIREQOg2WEqBUEQcDLk/vDz1OJ0xeqsHhzttSRiIgcBssIUSt16aTA4jubFtP7aE8efjpdKnEiIiLHwDJCZIHRvfxxT1w3AMBTazKhq22QOBERkf1jGSGy0LOTeqO7jwcKdXV4/ptjUschIrJ7LCNEFuqkdMGyqdGQCcC6g+ex+WiR1JGIiOwaywhRGwzq7o0ZIyMAACnrjuBCJRfTIyJqK5YRojaakxiJ3kEqXKppwIIvj3AxPSKiNmIZIWojhYsMK6bFQCGXYXvWBXzxS4HUkYiI7BLLCNENiAr0xFPjIgEAL357HPllNRInIiKyPywjRDfooRHhiAvzRk29EcmrtTCaeLmGiMgSLCNEN0guE7B0SjQ6KeTYf/YS3kvPlToSEZFdYRkhagcabw8sSmpaTG/Z1mwcL9RLnIiIyH6wjBC1kymDuyKxdwAajCKSV2thaORiekRErcEyQtROBEHAq3f2h08nBbKKKzHrs0MoKOeEViKi62EZIWpHvp2VeO3OARAEYOvxEtyydCf++fUxlFUZpI5GRGSzWEaI2llinwB8PXMERvTwRYNRxMqfzuDmxTvwxg+nUG1olDoeEZHNEUQ7uG2kXq+HWq2GTqeDSqWSOg5Rq/146iJe25yFo+ebJrT6dlbg8Vt64p64blC48P8FiMixtfb7m2WEyMpMJhEbjxRhyffZOHv5pmjdvD3w5NhIJA0IhkwmSJyQiMg6WEaIbEyD0YQvfinAGz+cQunlOSR9g1WYN74Xbu7pC0FgKSEix8IyQmSjqg2N+Gh3Hv6dnouqy3NIEsJ9sGBCL0RrvKQNR0TUjlhGiGxceXU90nacxv8yzqLeaAIATOwfiKfGRiHcr7PE6YiIbhzLCJGdOHepBsu2nsT6Q+chik23l586WIM5iT0RoHKTOh4RUZuxjBDZmaxiPV7fnI1tWRcAAG6uMjw4PAyPjoyA2t1V4nRERJZjGSGyU/vyyvHqdydwML8CAKB2d8XM0RGYnhAKN1e5tOGIiCzQ2u/vNt3oIC0tDaGhoXBzc0N8fDz27dt3zfErVqxAVFQU3N3dodFoMHfuXNTV1bXlqYkcXlyYN758bBjeu28Qevp3hq62Aa9sysLoJTuxen8BjCab//8HIiKLWFxGVq1aheTkZCxatAgHDx5EdHQ0xo0bhwsXLlx1/GeffYYFCxZg0aJFOHHiBD788EOsWrUK//jHP244PJGjEgQBY/sGYvOcm7H4rgEIUruhSFeHeWsPY/yKdHx/rBh2cFKTiKhVLL5MEx8fjyFDhuCtt94CAJhMJmg0Gjz++ONYsGDBFeNnzZqFEydOYNu2bebHnnzySfz888/YvXt3q56Tl2nI2dU1GPHfjDNI25EDXW0DAGBQ9y6YP74X4sK8JU5HRHR1VrlMU19fjwMHDiAxMfG3f0AmQ2JiIjIyMq66z7Bhw3DgwAHzpZzc3Fxs2rQJEydObPF5DAYD9Hp9s43Imbm5yvHIzRFInzcafx8VATdXGQ6cvYSp/87AQyt/QVYx/xshIvtlURkpLS2F0WhEQEBAs8cDAgJQXFx81X3uvfdevPDCCxgxYgRcXV0RERGBUaNGXfMyTWpqKtRqtXnTaDSWxCRyWGp3V8wb3wu7nh6Ne+K6QS4TsC3rAia88SOSV2tx7lKN1BGJiCxm9ZW6du7ciVdeeQVvv/02Dh48iHXr1mHjxo148cUXW9wnJSUFOp3OvBUUFFg7JpFdCVC5IfWO/vh+7s2Y2D8QogisO3getyzZhRe/PY7y6nqpIxIRtZqLJYN9fX0hl8tRUlLS7PGSkhIEBgZedZ/nnnsO9913Hx5++GEAQP/+/VFdXY1HHnkEzzzzDGSyK/uQUqmEUqm0JBqRU4rw64y3/zII2oIKvPZdFjJyy/Dh7jys/qUAj9wcjoduCoOHwqL/zImIOpxFZ0YUCgUGDRrUbDKqyWTCtm3bkJCQcNV9ampqrigccnnTvRL4awCi9hGj8cJnf4vHfx6MQ58gFSoNjVi69SRuXrwT/9t7Fg2XbzdPRGSLLP5fpuTkZNx///0YPHgw4uLisGLFClRXV+OBBx4AAEyfPh0hISFITU0FACQlJWHZsmWIjY1FfHw8Tp8+jeeeew5JSUnmUkJEN04QBIyM9MNNPXzxzeFCLP3+JPLLa/DchqP48MdcPDk2CpP6B0Em4+rARGRbLC4j06ZNw8WLF7Fw4UIUFxcjJiYGmzdvNk9qzc/Pb3Ym5Nlnn4UgCHj22Wdx/vx5+Pn5ISkpCS+//HL7vQoiMpPJBNwWE4IJ/YLw+b58vLn9FM6U1eDxzw/h3+k5WDC+N0b09JU6JhGRGW8HT+Tgqg2N+ODHPLyXnoPqeiMAYEQPX8wf3wv9u6olTkdEjoxr0xBRM6VVBry1/TQ+/fksGoxN/9lPGhCEp8ZGIcy3k8TpiMgRsYwQ0VUVlNdg2daT2KA9D1EEXGQC7o7T4Ilbe8Lf003qeETkQFhGiOiajhfqsXhLFnZmXwQAuLvK8dCIMDwyMhwqN1eJ0xGRI2AZIaJW2Ztbhle/y4K2oAIA0MXDFTNH98D/De0ON1f+4o2I2o5lhIhaTRRFbDlWgte3ZCHnYjUAIMTLHXPHROL22BDI+XNgImoDlhEislij0YS1B85hxQ+nUKyvAwBEBXhi3vgo3NLLH4LAUkJErccyQkRtVtdgxMqfzuDtHaehr2sEAAwJ7YIFE3phUHdvidMRkb1gGSGiG6aracDbu05j5Z4zMDQ23VI+sXcA5o2PQmSAp8TpiMjWsYwQUbsp0tXijR9OYfX+AphEQCYAdw7sirljIhHs5S51PCKyUSwjRNTuTl+owpIt2dh8rBgAoHCR4f6E7vj7qB7o0kkhcToisjUsI0RkNQfzL+G177Lwc145AMBT6YIZoyLwwPBQeCgsXvKKiBwUywgRWZUoith58iJe+y4LWcWVAAB/TyVmJ/bE1MEauMpl1/kXiMjRsYwQUYcwmUR8lXkeS78/iXOXagEAYb6d8NTYKEzsH8ifAxM5MZYRIupQhkYjPvs5H29uP43y6noAQHRXNeaP74VhPXwlTkdEUmAZISJJVBka8X56Lt7/MRc19UYAwE09fTF/fC/0C1FLnI6IOhLLCBFJ6mKlAW9tP4XP9uWjwdj0MfPn6GA8OTYS3X06SZyOiDoCywgR2YT8shos3ZqNr7SFAAAXmYB747vh8Vt6ws9TKXE6IrImlhEisilHz+uweEs20k9eBAB4KOR4eEQY/nZzODzdXCVOR0TWwDJCRDbpp5xSvPZdFjLP6QAA3p0UmDW6B/4ytBuULnKJ0xFRe2IZISKbJYoiNh8txutbspFbWg0A6NrFHcljInFbTAjkMv4cmMgRsIwQkc1rNJqwev85rPjhJC5UGgAAvQI9MX98L4yK8uM9SojsHMsIEdmN2nojPv4pD+/szEFlXSMAIC7MGwsm9MLAbl0kTkdEbcUyQkR2p6KmHm/vzMHKn86gvtEEABjXNwBPj4tCD39PidMRkaVYRojIbhVW1GLFDyex9sA5mERAJgBTBmkwZ0xPBKndpY5HRK3EMkJEdu9USSUWb8nG1uMlAACliwx/HRaKx0ZFwMtDIXE6IroelhEichgHzpbjte+yse9MOQBA5eaCx0b1wF+HhcJdwZ8DE9kqlhEiciiiKGJH9gW89l02sksqAQABKiXmJEZiyqCucJHLJE5IRH/EMkJEDsloErHh0Hks23oS5ytqAQDhfp0wb1wUxvUN5M+BiWwIywgROTRDoxGf7M3HW9tP4VJNAwAgRuOF+eN7ISHCR+J0RASwjBCRk9DXNeD99Fx88GMeahuMAICRkX6YP74X+gTz84JISiwjRORULlTW4c1tp/H5vnw0mkQIAnBbdDCeHBsFjbeH1PGInBLLCBE5pTOl1VjyfTa+PVwEAHCVC/hLfHfMuqUHfDsrJU5H5Fxa+/3dpunnaWlpCA0NhZubG+Lj47Fv375rjq+oqMDMmTMRFBQEpVKJyMhIbNq0qS1PTUR0TaG+nfDWvQPxzawRuKmnLxqMIlb+dAYjF+/Aih9OosrQKHVEIvoDi8vIqlWrkJycjEWLFuHgwYOIjo7GuHHjcOHChauOr6+vx5gxY3DmzBmsXbsW2dnZeP/99xESEnLD4YmIWtK/qxr/eygenzwUj/4halTXG7Hih1MYuXgHVu7JM99unoikZ/Flmvj4eAwZMgRvvfUWAMBkMkGj0eDxxx/HggULrhj/7rvv4vXXX0dWVhZcXV3bFJKXaYjoRphMIjYdLcKSLdk4U1YDAOjm7YEnx0YiaUAwZDL+HJjIGqxymaa+vh4HDhxAYmLib/+ATIbExERkZGRcdZ+vv/4aCQkJmDlzJgICAtCvXz+88sorMBqNljw1EVGbyWQC/jQgGFuTR+Klyf3g56lEfnkNZn+hxZ/e3I2d2RdgB9PniByWRWWktLQURqMRAQEBzR4PCAhAcXHxVffJzc3F2rVrYTQasWnTJjz33HNYunQpXnrppRafx2AwQK/XN9uIiG6Uq1yG/xvaHbueHoWnxkbCU+mC40V6/PXjX3DP+3uhLaiQOiKRU7L6/ZNNJhP8/f3x3nvvYdCgQZg2bRqeeeYZvPvuuy3uk5qaCrVabd40Go21YxKRE/FQuGDWLT2xa95oPDwiDAq5DHtzyzE5bQ8e++QAci5WSR2RyKlYVEZ8fX0hl8tRUlLS7PGSkhIEBgZedZ+goCBERkZCLv9tMavevXujuLgY9fX1V90nJSUFOp3OvBUUFFgSk4ioVbw7KfDsn/pg+1MjcefArhAE4LujxRi7PB0p6w6jWFcndUQip2BRGVEoFBg0aBC2bdtmfsxkMmHbtm1ISEi46j7Dhw/H6dOnYTL9NnP95MmTCAoKgkJx9SXAlUolVCpVs42IyFq6dvHA0qnR2Dz7ZiT29ofRJOLzfQUYtWQHXtucBV1tg9QRiRyaxZdpkpOT8f777+M///kPTpw4gcceewzV1dV44IEHAADTp09HSkqKefxjjz2G8vJyzJ49GydPnsTGjRvxyiuvYObMme33KoiI2kFUoCc+uH8I1sxIwKDuXVDXYMI7O3Nw8+Id+PeuHNQ1cOI9kTW4WLrDtGnTcPHiRSxcuBDFxcWIiYnB5s2bzZNa8/PzIZP91nE0Gg22bNmCuXPnYsCAAQgJCcHs2bMxf/789nsVRETtaEioN9bOSMAPJy5g8eYsnLpQhdTvsrDypzOYmxiJOwaGwEVu9Sl3RE6Dt4MnIroGo0nEuoPnsHzrSRRenkPSw78znh4XhbF9AiAIvEcJUUu4Ng0RUTuqazDifxlnkbbzNCpqmuaQDOzmhfnjeyE+3EfidES2iWWEiMgKdLUNeC89Bx/uzkNdQ9PE/Ft6+WPe+Cj0CuTnE9HvsYwQEVlRib4Ob2w7hVW/FMBoEiEIwO0xIZg7JhIabw+p4xHZBJYRIqIOkHuxCku/P4mNR4oAAIrLd3mddUsPeHe6+u0LiJwFywgRUQfKLKjAa5uz8FNOGQCgs9IFj9wcjodGhKGT0uIfLhI5BJYRIqIOJooifjxVitc2Z+FYYdOaWr6dlZh9aw/cHdcNrvw5MDkZlhEiIomYTCK+PVKEpd9n42xZDQCgu48HnhwbhT/1D4JMxp8Dk3NgGSEiklh9owlf/JKPf207hdKqprW4+oWoMH98L9zU00/idETWxzJCRGQjqg2N+HB3Ht5Lz0WVoREAMLyHD+aP74UBXb2kDUdkRSwjREQ2pqzKgLd2nMYne8+iwdj00TupfxCeGheFMN9OEqcjan8sI0RENqqgvAbLt57Eeu15iCIglwm4e4gGs2/tCX+Vm9TxiNoNywgRkY07UaTH4s1Z2JF9EQDg7irHgyNC8ejICKjcXCVOR3TjWEaIiOzEz7lleHVzFg7lVwAAvDxcMWt0D/zf0O5wc5VLG47oBrCMEBHZEVEU8f3xEry+JRunL1QBAILVbpg7JhJ3DOwKOX8OTHaIZYSIyA41Gk348uA5LN96CsX6OgBAZEBnPD2uFxJ7+0MQWErIfrCMEBHZsboGI/7z0xm8vTMHutoGAMDg7l0w85YeGBrmA3cFL9+Q7WMZISJyALqaBryzKwcf78mDodEEAHCVC4jReGFouA8Swn0wsHsXzi0hm8QyQkTkQIp1dUjbcRpbj5eYL9/8SiGXNZWTCB8MDffGwG4sJ2QbWEaIiByQKIo4W1aDvbll2JtbhozcMpToDc3GKFxkiP31zEmED2I0XiwnJAmWESIiJyCKIs6U1SAj57dycrHyynIysJsXEsJ9MTTcGzHdvKB0YTkh62MZISJyQqIoIre0+vKZk3Jk5JShtKp5OVG6yDCoexfzmZPorl5QuMgkSkyOjGWEiIggiiJyLlabz5r8nFtmXkH4V26uTeUkIdwHQ8N9MIDlhNoJywgREV2hqZxUXb6sU469uWUoq25eTtxd5Rgc2nTmpKmcqOEqZzkhy7GMEBHRdYmiiFMXqprOnFyed3KppqHZGA+FvOnMSURTOekfwnJCrcMyQkREFjOZmspJRk5p05mTvDJU/KGcdFLIMTjU+/KZE2/0D1HDheWEroJlhIiIbpjJJCK7pNJ85uTnvHLzHWF/1Ukhx5Awb/Ock77BKpYTAsAyQkREVmAyicgqrkTG5fuc/JxbBn1dY7MxnkoXDAnzxtBwbySE+6JPsIoL/TkplhEiIrI6o0nEiSK9+afEP+eVofIq5SQuzNs856R3EMuJs2AZISKiDvdrOfl1Muy+vHJUGpqXE5WbC+LCmuabJET4oHegCjKWE4fEMkJERJIzmkQcK9SZz5zsyytH1R/KidrdtenMyeU5J70CPVlOHATLCBER2ZxGownHCvXmm7D9kleO6npjszFeHq6ID/M23yE20p/lxF6xjBARkc1rNJpw5LzOfAO2X86Uo+YP5aSLhyviw3zMc056+ndmObETLCNERGR3GszlpOmnxPvPXEJtQ/Ny4t1JgaHh3uY7xPb07wxBYDmxRVYtI2lpaXj99ddRXFyM6OhovPnmm4iLi7vufl988QXuuece3HbbbdiwYUOrn49lhIjIOTUYTTh8rqLZmZO6BlOzMT6dFOYbsCVE+CDCj+XEVlitjKxatQrTp0/Hu+++i/j4eKxYsQJr1qxBdnY2/P39W9zvzJkzGDFiBMLDw+Ht7c0yQkREFqtv/LWcNM052X/mEgyNzcuJb2dlszMnEX6dWE4kYrUyEh8fjyFDhuCtt94CAJhMJmg0Gjz++ONYsGDBVfcxGo24+eab8eCDD+LHH39ERUUFywgREd0wQ6MRh8/pzD8lPnD2ynLi56n87cxJuA/CfFlOOkprv79dLPlH6+vrceDAAaSkpJgfk8lkSExMREZGRov7vfDCC/D398dDDz2EH3/88brPYzAYYDAYzH/W6/WWxCQiIiehdJFjSKg3hoR644lbe8LQaIQ2v+myTkZuKQ7mV+BipQHfZBbim8xCAECASmk+azI03AehPh4sJxKzqIyUlpbCaDQiICCg2eMBAQHIysq66j67d+/Ghx9+CK1W2+rnSU1NxfPPP29JNCIiIihd5IgP90F8uA9moyfqGozQFlSYz5wcyq9Aid6Ar7SF+ErbVE4CVW7myzoJET7o5s1y0tEsKiOWqqysxH333Yf3338fvr6+rd4vJSUFycnJ5j/r9XpoNBprRCQiIgfm5io3nwEBgLoGIw7mX2qaEJtThkMFl1Csr8MGbSE2XC4nQWo38w3Yhob7QOPtznJiZRaVEV9fX8jlcpSUlDR7vKSkBIGBgVeMz8nJwZkzZ5CUlGR+zGRqupbn4uKC7OxsREREXLGfUqmEUqm0JBoREdF1ubnKMSzCF8MifIExQG29EYfyL5kX/tMWVKBIV4d1h85j3aHzAIAQL3fEh/92h1iNt4fEr8LxtGkCa1xcHN58800ATeWiW7dumDVr1hUTWOvq6nD69Olmjz377LOorKzEG2+8gcjISCgUius+JyewEhFRR6itN+LA2UuXb1/fVE4aTc2/JkO83M03YBsa7o2uXVhOWmKVCawAkJycjPvvvx+DBw9GXFwcVqxYgerqajzwwAMAgOnTpyMkJASpqalwc3NDv379mu3v5eUFAFc8TkREJDV3hRwjevpiRM+mqQU19Y3mcpKRU4bD53Q4X1GLtQfOYe2BcwAAjbc7hob5mOecBHu5S/kS7JLFZWTatGm4ePEiFi5ciOLiYsTExGDz5s3mSa35+fmQyWTtHpSIiKijeShccFNPP9zU0w8AUG1oxP7fnTk5fE6HgvJaFJSfw5rL5aSbt4f5BmxDw30QpGY5uR7eDp6IiKiNqgyN2H+m/PJPictw9LwOxj9c1gn18Wj2U+JAtZtEaTse16YhIiLqYJV1Ddh/5rczJ0fO6/CHboIw306//ZQ43Af+KsctJywjREREEtPXNfx25iSnDMcKrywn4X6dfnfmxBv+no5TTlhGiIiIbIyutqmcZOSUYW9eGY4V6vHHb+GIy+UkIcIH8WE+8PO031tdsIwQERHZOF1NA/adKTf/WudE8ZXlpKd/52ZnTnw62085YRkhIiKyMxU19diXV375JmzlOFF05dpskQGdzfNN4sN94N3p+vfrkgrLCBERkZ27VF2Pn/PKzRNis4orrxjTK9DTfNYkPswHXWyonLCMEBEROZjy6nrsyyu7vPBfObJLWi4nTXNOvOHlIV05YRkhIiJycGVVhmZnTk6WVDX7e0EAegWqLq+r03TmRO3h2mH5WEaIiIicTGmVAT/nliMjtxR7c8tx+sKV5aRPkMo852RImDfU7tYrJywjRERETu5ipcF81mRvbhlyLlY3+3tBAPoGN505uS0mBP1C1O36/FZbKI+IiIjsg5+nEknRwUiKDgYAXNDXYe+vl3VyypBbWo2j5/U4el6PqEBVu5eR1mIZISIichL+Kjf8OToYf75cTkr0deazJsMifCTLxcs0REREZBWt/f6WdWAmIiIioiuwjBAREZGkWEaIiIhIUiwjREREJCmWESIiIpIUywgRERFJimWEiIiIJMUyQkRERJJiGSEiIiJJsYwQERGRpFhGiIiISFIsI0RERCQplhEiIiKSlIvUAVrj14WF9Xq9xEmIiIiotX793v71e7wldlFGKisrAQAajUbiJERERGSpyspKqNXqFv9eEK9XV2yAyWRCYWEhPD09IQhCu/27er0eGo0GBQUFUKlU7fbvOioer9bjsWo9HqvW47FqPR6r1rPmsRJFEZWVlQgODoZM1vLMELs4MyKTydC1a1er/fsqlYpvVgvweLUej1Xr8Vi1Ho9V6/FYtZ61jtW1zoj8ihNYiYiISFIsI0RERCQppy4jSqUSixYtglKplDqKXeDxaj0eq9bjsWo9HqvW47FqPVs4VnYxgZWIiIgcl1OfGSEiIiLpsYwQERGRpFhGiIiISFIsI0RERCQphy8jaWlpCA0NhZubG+Lj47Fv375rjl+zZg169eoFNzc39O/fH5s2beqgpNKz5FitXLkSgiA029zc3DowrXTS09ORlJSE4OBgCIKADRs2XHefnTt3YuDAgVAqlejRowdWrlxp9Zy2wNJjtXPnziveV4IgoLi4uGMCSyg1NRVDhgyBp6cn/P39MXnyZGRnZ193P2f8zGrLsXLWz6x33nkHAwYMMN/QLCEhAd99990195HiPeXQZWTVqlVITk7GokWLcPDgQURHR2PcuHG4cOHCVcf/9NNPuOeee/DQQw/h0KFDmDx5MiZPnoyjR492cPKOZ+mxApru1ldUVGTezp4924GJpVNdXY3o6GikpaW1anxeXh4mTZqE0aNHQ6vVYs6cOXj44YexZcsWKyeVnqXH6lfZ2dnN3lv+/v5WSmg7du3ahZkzZ2Lv3r3YunUrGhoaMHbsWFRXV7e4j7N+ZrXlWAHO+ZnVtWtXvPrqqzhw4AD279+PW265BbfddhuOHTt21fGSvadEBxYXFyfOnDnT/Gej0SgGBweLqampVx0/depUcdKkSc0ei4+PFx999FGr5rQFlh6rjz/+WFSr1R2UznYBENevX3/NMfPmzRP79u3b7LFp06aJ48aNs2Iy29OaY7Vjxw4RgHjp0qUOyWTLLly4IAIQd+3a1eIYZ/7M+r3WHCt+Zv2mS5cu4gcffHDVv5PqPeWwZ0bq6+tx4MABJCYmmh+TyWRITExERkbGVffJyMhoNh4Axo0b1+J4R9GWYwUAVVVV6N69OzQazTWbtrNz1vfVjYiJiUFQUBDGjBmDPXv2SB1HEjqdDgDg7e3d4hi+t5q05lgB/MwyGo344osvUF1djYSEhKuOkeo95bBlpLS0FEajEQEBAc0eDwgIaPH6c3FxsUXjHUVbjlVUVBQ++ugjfPXVV/jkk09gMpkwbNgwnDt3riMi25WW3ld6vR61tbUSpbJNQUFBePfdd/Hll1/iyy+/hEajwahRo3Dw4EGpo3Uok8mEOXPmYPjw4ejXr1+L45z1M+v3WnusnPkz68iRI+jcuTOUSiVmzJiB9evXo0+fPlcdK9V7yi5W7SXbk5CQ0KxZDxs2DL1798a///1vvPjiixImI3sWFRWFqKgo85+HDRuGnJwcLF++HP/73/8kTNaxZs6ciaNHj2L37t1SR7F5rT1WzvyZFRUVBa1WC51Oh7Vr1+L+++/Hrl27WiwkUnDYMyO+vr6Qy+UoKSlp9nhJSQkCAwOvuk9gYKBF4x1FW47VH7m6uiI2NhanT5+2RkS71tL7SqVSwd3dXaJU9iMuLs6p3lezZs3Ct99+ix07dqBr167XHOusn1m/suRY/ZEzfWYpFAr06NEDgwYNQmpqKqKjo/HGG29cdaxU7ymHLSMKhQKDBg3Ctm3bzI+ZTCZs27atxWtlCQkJzcYDwNatW1sc7yjacqz+yGg04siRIwgKCrJWTLvlrO+r9qLVap3ifSWKImbNmoX169dj+/btCAsLu+4+zvreasux+iNn/swymUwwGAxX/TvJ3lNWnR4rsS+++EJUKpXiypUrxePHj4uPPPKI6OXlJRYXF4uiKIr33XefuGDBAvP4PXv2iC4uLuKSJUvEEydOiIsWLRJdXV3FI0eOSPUSOoylx+r5558Xt2zZIubk5IgHDhwQ7777btHNzU08duyYVC+hw1RWVoqHDh0SDx06JAIQly1bJh46dEg8e/asKIqiuGDBAvG+++4zj8/NzRU9PDzEp59+Wjxx4oSYlpYmyuVycfPmzVK9hA5j6bFavny5uGHDBvHUqVPikSNHxNmzZ4symUz84YcfpHoJHeaxxx4T1Wq1uHPnTrGoqMi81dTUmMfwM6tJW46Vs35mLViwQNy1a5eYl5cnHj58WFywYIEoCIL4/fffi6JoO+8phy4joiiKb775ptitWzdRoVCIcXFx4t69e81/N3LkSPH+++9vNn716tViZGSkqFAoxL59+4obN27s4MTSseRYzZkzxzw2ICBAnDhxonjw4EEJUne8X39++sft1+Nz//33iyNHjrxin5iYGFGhUIjh4eHixx9/3OG5pWDpsXrttdfEiIgI0c3NTfT29hZHjRolbt++XZrwHexqxwlAs/cKP7OatOVYOetn1oMPPih2795dVCgUop+fn3jrrbeai4go2s57ShBFUbTuuRciIiKiljnsnBEiIiKyDywjREREJCmWESIiIpIUywgRERFJimWEiIiIJMUyQkRERJJiGSEiIiJJsYwQERGRpFhGiIiISFIsI0RERCQplhEiIiKSFMsIERERSer/ATlKnaOkv0dzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 20, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktCoIc8AwvVX",
        "outputId": "af051f0f-d6bf-468c-f7bb-8b75e9774882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> you are so childish sometimes\n",
            "= vous etes parfois si pueriles\n",
            "< tu es parfois si puerile <EOS>\n",
            "Accuracy for this pair: 0.4\n",
            "\n",
            "> you re my kid s teacher\n",
            "= vous etes l institutrice de mon enfant\n",
            "< vous etes l institutrice de mon enfant <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> i m always careful\n",
            "= je suis toujours prudente\n",
            "< je suis toujours faim <EOS>\n",
            "Accuracy for this pair: 0.75\n",
            "\n",
            "> i m your sister\n",
            "= je suis ta s ur\n",
            "< je suis votre s ur <EOS>\n",
            "Accuracy for this pair: 0.8\n",
            "\n",
            "> i m really glad i ran into you\n",
            "= je suis vraiment content d etre tombe sur toi\n",
            "< je suis vraiment content de vous avoir fait attendre <EOS>\n",
            "Accuracy for this pair: 0.4444444444444444\n",
            "\n",
            "> he is unable to buy a car\n",
            "= il est incapable d acheter une voiture\n",
            "< il est incapable d acheter une voiture <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> i m sure\n",
            "= j en suis sur\n",
            "< je suis sure que moi <EOS>\n",
            "Accuracy for this pair: 0.0\n",
            "\n",
            "> we re in love\n",
            "= nous nous aimons\n",
            "< nous sommes amoureuses <EOS>\n",
            "Accuracy for this pair: 0.3333333333333333\n",
            "\n",
            "> you re not allowed to eat those\n",
            "= vous n etes pas autorisees a manger ceux la\n",
            "< vous n etes pas autorisees a manger ceux ci <EOS>\n",
            "Accuracy for this pair: 0.8888888888888888\n",
            "\n",
            "> i m too tired to think\n",
            "= je suis trop fatigue pour penser\n",
            "< je suis trop fatigue pour reflechir bien <EOS>\n",
            "Accuracy for this pair: 0.8333333333333334\n",
            "\n",
            "Overall accuracy: 0.6949152542372882\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SXpyFhlJNfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b663b91-c902-437d-f1b6-3b35c364a0e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Accuracy with Attention Model: 0.9365\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    \"\"\"\n",
        "    Function to calculate accuracy.\n",
        "    \"\"\"\n",
        "    return np.mean(np.array(predictions) == np.array(targets))\n",
        "\n",
        "def evaluate_accuracy(encoder, decoder, dataloader, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Function to evaluate accuracy on a dataset.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            input_tensor, target_tensor = data\n",
        "\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            _, topi = decoder_outputs.topk(1)\n",
        "            decoded_ids = topi.squeeze()\n",
        "\n",
        "            for idx_tensor, target_tensor in zip(decoded_ids, target_tensor.squeeze()):\n",
        "                for idx in idx_tensor:\n",
        "                    idx = idx.item()  # Convert tensor element to scalar\n",
        "                    if idx == EOS_token:\n",
        "                        predictions.append('<EOS>')\n",
        "                    else:\n",
        "                        predictions.append(output_lang.index2word[idx])\n",
        "\n",
        "\n",
        "                for target_idx in target_tensor:\n",
        "                    target = target_idx.item()  # Convert tensor element to scalar\n",
        "                    if target == EOS_token:\n",
        "                        targets.append('<EOS>')\n",
        "                    else:\n",
        "                        targets.append(output_lang.index2word[target])\n",
        "\n",
        "    return calculate_accuracy(predictions, targets)\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        for idx, target_idx in zip(decoded_ids, target_tensor.squeeze()):\n",
        "            if idx.item() == EOS_token:\n",
        "                predictions.append('<EOS>')\n",
        "            else:\n",
        "                predictions.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "            if target_idx.item() == EOS_token:\n",
        "                targets.append('<EOS>')\n",
        "            else:\n",
        "                targets.append(output_lang.index2word[target_idx.item()])\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = calculate_accuracy(predictions, targets)\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "            print(\"Training Accuracy: %.4f\" % accuracy)\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "# Evaluate training accuracy\n",
        "train_accuracy = evaluate_accuracy(encoder, decoder, train_dataloader, input_lang, output_lang)\n",
        "print(\"Final Training Accuracy with Attention Model: %.4f\" % train_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV9vXNmlzKT8"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpXNNDuZzGf-"
      },
      "source": [
        "# FRENCH-ENGLISH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3W-KkDJJNcO"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    \"\"\"\n",
        "    Represents a language class used for word indexing and counting.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the language.\n",
        "\n",
        "    Attributes:\n",
        "        name (str): The name of the language.\n",
        "        word2index (dict): A dictionary mapping words to their corresponding indices.\n",
        "        word2count (dict): A dictionary mapping words to their count in the language.\n",
        "        index2word (dict): A dictionary mapping indices to their corresponding words.\n",
        "        n_words (int): The total number of unique words in the language.\n",
        "\n",
        "    Methods:\n",
        "        addSentence(sentence): Splits a sentence into words and adds each word to the language.\n",
        "        addWord(word): Adds a word to the language, updating its index and count if it's new.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}  # Dictionary to map words to indices\n",
        "        self.word2count = {}  # Dictionary to count the occurrences of each word\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}  # Mapping indices to words, initialized with SOS and EOS tokens\n",
        "        self.n_words = 2  # Count of unique words, initialized with SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        \"\"\"\n",
        "        Splits a sentence into words and adds each word to the language.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): The input sentence to be processed.\n",
        "        \"\"\"\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        \"\"\"\n",
        "        Adds a word to the language, updating its index and count if it's new.\n",
        "\n",
        "        Args:\n",
        "            word (str): The word to be added to the language.\n",
        "        \"\"\"\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDqP3FICxNT7"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    \"\"\"\n",
        "    Converts a Unicode string to ASCII.\n",
        "\n",
        "    Args:\n",
        "        s (str): The Unicode string to be converted.\n",
        "\n",
        "    Returns:\n",
        "        str: The ASCII representation of the input Unicode string.\n",
        "    \"\"\"\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    \"\"\"\n",
        "    Lowercases, trims, and removes non-letter characters from a string.\n",
        "\n",
        "    Args:\n",
        "        s (str): The input string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        str: The normalized string.\n",
        "    \"\"\"\n",
        "    s = unicodeToAscii(s.lower().strip())  # Convert to ASCII, lowercase, and strip whitespace\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)  # Add space before punctuation marks\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)  # Remove non-letter characters\n",
        "    return s.strip()  # Trim leading and trailing spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CWU6yVexTqV"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    \"\"\"\n",
        "    Reads language data from a file and creates language instances.\n",
        "\n",
        "    Args:\n",
        "        lang1 (str): The name of the first language.\n",
        "        lang2 (str): The name of the second language.\n",
        "        reverse (bool, optional): If True, reverses the language pairs. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Lang, Lang, List[List[str]]]: A tuple containing two language instances\n",
        "        and a list of language pairs.\n",
        "    \"\"\"\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('/content/eng-fra.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWxPYKyaunN3"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    \"\"\"\n",
        "    Determines whether a pair of sentences meets the maximum length constraint and starts with an English prefix.\n",
        "\n",
        "    Args:\n",
        "        p (Tuple[str, str]): A pair of sentences (source and target).\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the pair meets the criteria, False otherwise.\n",
        "    \"\"\"\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    \"\"\"\n",
        "    Filters pairs of sentences based on length and English prefixes.\n",
        "\n",
        "    Args:\n",
        "        pairs (List[Tuple[str, str]]): A list of sentence pairs (source and target).\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: Filtered list of sentence pairs.\n",
        "    \"\"\"\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bebq4-C_w49H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186e122e-e33a-432f-9ad0-0bca775163bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "['je suis etudiant a l universite', 'i am a university student']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    \"\"\"\n",
        "    Prepares the data for language translation by reading sentence pairs,\n",
        "    filtering them based on length and prefixes, counting words, and creating language instances.\n",
        "\n",
        "    Args:\n",
        "        lang1 (str): The language code of the source language.\n",
        "        lang2 (str): The language code of the target language.\n",
        "        reverse (bool, optional): Flag to reverse the order of language pairs. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Tuple: A tuple containing input and output language instances, and filtered sentence pairs.\n",
        "    \"\"\"\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDR2PAq6zqm9"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko_EexPgJNZi"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder RNN module for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): The size of the input vocabulary.\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "        dropout_p (float, optional): Dropout probability. Defaults to 0.1.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Forward pass of the Encoder RNN.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor of shape (batch_size, seq_len).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, hidden_size).\n",
        "            torch.Tensor: Hidden state tensor of shape (1, batch_size, hidden_size).\n",
        "        \"\"\"\n",
        "        # Embed input\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # Forward pass through GRU\n",
        "        output, hidden = self.gru(embedded)\n",
        "\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tY8bWbc0EXM"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS7PXb3PJNW7"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder RNN module for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "        output_size (int): The size of the output vocabulary.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the Decoder RNN.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Tensor containing the output features from the encoder.\n",
        "            encoder_hidden (torch.Tensor): Tensor containing the hidden state of the encoder.\n",
        "            target_tensor (torch.Tensor, optional): Tensor containing the target sequence. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, output_size).\n",
        "            torch.Tensor: Hidden state tensor of shape (1, batch_size, hidden_size).\n",
        "            None: Placeholder for consistency in the training loop.\n",
        "        \"\"\"\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None  # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        \"\"\"\n",
        "        Forward step of the Decoder RNN.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Tensor containing the input sequence.\n",
        "            hidden (torch.Tensor): Tensor containing the hidden state.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_len, hidden_size).\n",
        "            torch.Tensor: Hidden state tensor of shape (1, batch_size, hidden_size).\n",
        "        \"\"\"\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmeZYSxY0LDb"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9AEkkE2JNUX"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Bahdanau Attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        \"\"\"\n",
        "        Forward pass of the Bahdanau Attention mechanism.\n",
        "\n",
        "        Args:\n",
        "            query (torch.Tensor): Query tensor.\n",
        "            keys (torch.Tensor): Keys tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Context tensor.\n",
        "            torch.Tensor: Attention weights.\n",
        "        \"\"\"\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder RNN with Bahdanau Attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): The size of the hidden state.\n",
        "        output_size (int): The size of the output vocabulary.\n",
        "        dropout_p (float, optional): Dropout probability. Defaults to 0.1.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the AttnDecoderRNN.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Encoder outputs.\n",
        "            encoder_hidden (torch.Tensor): Encoder hidden state.\n",
        "            target_tensor (torch.Tensor, optional): Target tensor. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Decoder outputs.\n",
        "            torch.Tensor: Decoder hidden state.\n",
        "            torch.Tensor: Attention weights.\n",
        "        \"\"\"\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        Forward step of the AttnDecoderRNN.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor.\n",
        "            hidden (torch.Tensor): Hidden state tensor.\n",
        "            encoder_outputs (torch.Tensor): Encoder outputs tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor.\n",
        "            torch.Tensor: Hidden state tensor.\n",
        "            torch.Tensor: Attention weights tensor.\n",
        "        \"\"\"\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcon51yA1I4b"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBJ7FJuGJNR-"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    \"\"\"\n",
        "    Convert a sentence to a list of its corresponding token indexes.\n",
        "\n",
        "    Args:\n",
        "        lang (Lang): Language object containing word-to-index mapping.\n",
        "        sentence (str): Input sentence.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: List of token indexes.\n",
        "    \"\"\"\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    \"\"\"\n",
        "    Convert a sentence to a tensor with token indexes and EOS token.\n",
        "\n",
        "    Args:\n",
        "        lang (Lang): Language object containing word-to-index mapping.\n",
        "        sentence (str): Input sentence.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Tensor of token indexes with EOS token.\n",
        "    \"\"\"\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    \"\"\"\n",
        "    Generate input and target tensors from a pair of sentences.\n",
        "\n",
        "    Args:\n",
        "        pair (tuple): Pair of input and target sentences.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Input and target tensors.\n",
        "    \"\"\"\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    \"\"\"\n",
        "    Generate a DataLoader for training data.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): Batch size for DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Input language, output language, and DataLoader.\n",
        "    \"\"\"\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder-Decoder Model Training"
      ],
      "metadata": {
        "id": "swxhD2rl0ybb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc1Sa83OJNPY"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Train one epoch of the sequence-to-sequence model.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): DataLoader for training data.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        encoder_optimizer (torch.optim.Optimizer): Optimizer for the encoder.\n",
        "        decoder_optimizer (torch.optim.Optimizer): Optimizer for the decoder.\n",
        "        criterion (torch.nn.Module): Loss criterion.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss over the epoch.\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgI0CmdoKp7d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    \"\"\"\n",
        "    Convert seconds to minutes and seconds.\n",
        "\n",
        "    Args:\n",
        "        s (float): Time in seconds.\n",
        "\n",
        "    Returns:\n",
        "        str: Time formatted as minutes and seconds.\n",
        "    \"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    \"\"\"\n",
        "    Calculate the elapsed time since a given time and estimate remaining time.\n",
        "\n",
        "    Args:\n",
        "        since (float): The start time.\n",
        "        percent (float): The completion percentage.\n",
        "\n",
        "    Returns:\n",
        "        str: Elapsed time and estimated remaining time.\n",
        "    \"\"\"\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZLo7OpS2D8t"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    \"\"\"\n",
        "    Plot the given points and set major tick locators at regular intervals.\n",
        "\n",
        "    Args:\n",
        "        points (array_like): The data points to plot.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Define the tick locator to put ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "\n",
        "    # Plot the points\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gyQi5x12EgX"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    \"\"\"\n",
        "    Train the encoder-decoder model for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        train_dataloader (DataLoader): DataLoader for the training dataset.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n_epochs (int): Number of epochs for training.\n",
        "        learning_rate (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
        "        print_every (int, optional): Frequency of printing training progress. Default is 100.\n",
        "        plot_every (int, optional): Frequency of plotting losses. Default is 100.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9A5tL4V2Epk"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on a single sentence.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        sentence (str): Input sentence to be translated.\n",
        "        input_lang (Lang): Input language object containing word-to-index and index-to-word mappings.\n",
        "        output_lang (Lang): Output language object containing word-to-index and index-to-word mappings.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Tensor]: A tuple containing the list of decoded words and the decoder attention.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)  # Convert input sentence to tensor\n",
        "\n",
        "        # Encode input sentence\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        # Decode using the encoder outputs and hidden state\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        # Get the index of the highest probability output token for each timestep\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:  # If end of sentence token, append '<EOS>' and break\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])  # Append the decoded word\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-kC0iif2ExB"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on random input-output pairs.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n (int): Number of pairs to evaluate. Defaults to 10.\n",
        "    \"\"\"\n",
        "    total_correct = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)  # Choose a random pair from the dataset\n",
        "        print('>', pair[0])  # Print the input sequence\n",
        "        print('=', pair[1])  # Print the target output sequence\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)  # Evaluate the pair\n",
        "        output_sentence = ' '.join(output_words)  # Convert the list of output words to a sentence\n",
        "        print('<', output_sentence)  # Print the generated output sequence\n",
        "\n",
        "        # Calculate accuracy\n",
        "        target_words = pair[1].split()\n",
        "        correct = sum(1 for pred, target in zip(output_words, target_words) if pred == target)\n",
        "        total_correct += correct\n",
        "        total_words += len(target_words)\n",
        "\n",
        "        print('Accuracy for this pair:', correct / len(target_words))  # Print accuracy for this pair\n",
        "        print('')  # Print an empty line for clarity\n",
        "\n",
        "    print('Overall accuracy:', total_correct / total_words)  # Print overall accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 20, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "TwkTYruJwtpN",
        "outputId": "63337a58-2fe2-42d0-b34d-f9929b0160d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "2m 41s (- 8m 5s) (5 25%) 1.7350\n",
            "5m 25s (- 5m 25s) (10 50%) 0.9750\n",
            "8m 6s (- 2m 42s) (15 75%) 0.6676\n",
            "10m 46s (- 0m 0s) (20 100%) 0.4789\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-5P4uNpwtXE",
        "outputId": "fa52faf2-c4ea-49ba-c4dd-37f750d50ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> il n est pas idiot\n",
            "= he s not stupid\n",
            "< he isn t really not interested in history <EOS>\n",
            "Accuracy for this pair: 0.25\n",
            "\n",
            "> ma vie pour une biere !\n",
            "= i m dying for a beer !\n",
            "< i m getting a little dizzy <EOS>\n",
            "Accuracy for this pair: 0.2857142857142857\n",
            "\n",
            "> vous etes toujours vivant\n",
            "= you re still alive\n",
            "< you re always finding fault with me <EOS>\n",
            "Accuracy for this pair: 0.5\n",
            "\n",
            "> je suis un electricien\n",
            "= i am an electrician\n",
            "< i m a stranger here for your advice <EOS>\n",
            "Accuracy for this pair: 0.25\n",
            "\n",
            "> elles n ont pas toujours raison\n",
            "= they re not always right\n",
            "< they re not always right <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> tu es grand\n",
            "= you re big\n",
            "< you re very clever here <EOS>\n",
            "Accuracy for this pair: 0.6666666666666666\n",
            "\n",
            "> je suis impatient de te revoir\n",
            "= i am looking forward to seeing you again\n",
            "< i m glad that makes you happy <EOS>\n",
            "Accuracy for this pair: 0.125\n",
            "\n",
            "> elle est toujours soignee et ordonnee\n",
            "= she is always neat and tidy\n",
            "< she is always finding fault with others <EOS>\n",
            "Accuracy for this pair: 0.5\n",
            "\n",
            "> je romps ce soir avec ma petite amie\n",
            "= i m breaking up with my girlfriend tonight\n",
            "< i m breaking up with my girlfriend tonight <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> je suis sure que tout va rouler\n",
            "= i m sure everything will work out just fine\n",
            "< i m sure we ll win the game <EOS>\n",
            "Accuracy for this pair: 0.3333333333333333\n",
            "\n",
            "Overall accuracy: 0.4827586206896552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UwbSFcY2E6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78b44fc-b692-4ab3-bfed-8f6f34f4d484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Accuracy without Attention: 0.9152\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    \"\"\"\n",
        "    Function to calculate accuracy.\n",
        "    \"\"\"\n",
        "    return np.mean(np.array(predictions) == np.array(targets))\n",
        "\n",
        "def evaluate_accuracy(encoder, decoder, dataloader, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Function to evaluate accuracy on a dataset.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            input_tensor, target_tensor = data\n",
        "\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            _, topi = decoder_outputs.topk(1)\n",
        "            decoded_ids = topi.squeeze()\n",
        "\n",
        "            for idx_tensor, target_tensor in zip(decoded_ids, target_tensor.squeeze()):\n",
        "                for idx in idx_tensor:\n",
        "                    idx = idx.item()  # Convert tensor element to scalar\n",
        "                    if idx == EOS_token:\n",
        "                        predictions.append('<EOS>')\n",
        "                    else:\n",
        "                        predictions.append(output_lang.index2word[idx])\n",
        "\n",
        "\n",
        "                for target_idx in target_tensor:\n",
        "                    target = target_idx.item()  # Convert tensor element to scalar\n",
        "                    if target == EOS_token:\n",
        "                        targets.append('<EOS>')\n",
        "                    else:\n",
        "                        targets.append(output_lang.index2word[target])\n",
        "\n",
        "    return calculate_accuracy(predictions, targets)\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        for idx, target_idx in zip(decoded_ids, target_tensor.squeeze()):\n",
        "            if idx.item() == EOS_token:\n",
        "                predictions.append('<EOS>')\n",
        "            else:\n",
        "                predictions.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "            if target_idx.item() == EOS_token:\n",
        "                targets.append('<EOS>')\n",
        "            else:\n",
        "                targets.append(output_lang.index2word[target_idx.item()])\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = calculate_accuracy(predictions, targets)\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "            print(\"Training Accuracy: %.4f\" % accuracy)\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "# Evaluate training accuracy\n",
        "train_accuracy = evaluate_accuracy(encoder, decoder, train_dataloader, input_lang, output_lang)\n",
        "print(\"Final Training Accuracy without Attention: %.4f\" % train_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Model Training"
      ],
      "metadata": {
        "id": "28ZQpPihz0bf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b54X0AsB6MZq"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Train one epoch of the sequence-to-sequence model.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): DataLoader for training data.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        encoder_optimizer (torch.optim.Optimizer): Optimizer for the encoder.\n",
        "        decoder_optimizer (torch.optim.Optimizer): Optimizer for the decoder.\n",
        "        criterion (torch.nn.Module): Loss criterion.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss over the epoch.\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ5SH8_s6MNq"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    \"\"\"\n",
        "    Convert seconds to minutes and seconds.\n",
        "\n",
        "    Args:\n",
        "        s (float): Time in seconds.\n",
        "\n",
        "    Returns:\n",
        "        str: Time formatted as minutes and seconds.\n",
        "    \"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    \"\"\"\n",
        "    Calculate the elapsed time since a given time and estimate remaining time.\n",
        "\n",
        "    Args:\n",
        "        since (float): The start time.\n",
        "        percent (float): The completion percentage.\n",
        "\n",
        "    Returns:\n",
        "        str: Elapsed time and estimated remaining time.\n",
        "    \"\"\"\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j5-UojO6MET"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    \"\"\"\n",
        "    Plot the given points and set major tick locators at regular intervals.\n",
        "\n",
        "    Args:\n",
        "        points (array_like): The data points to plot.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Define the tick locator to put ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "\n",
        "    # Plot the points\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BS9VYlf6MAu"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    \"\"\"\n",
        "    Train the encoder-decoder model for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        train_dataloader (DataLoader): DataLoader for the training dataset.\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n_epochs (int): Number of epochs for training.\n",
        "        learning_rate (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
        "        print_every (int, optional): Frequency of printing training progress. Default is 100.\n",
        "        plot_every (int, optional): Frequency of plotting losses. Default is 100.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4Mcwbe76L7u"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on a single sentence.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        sentence (str): Input sentence to be translated.\n",
        "        input_lang (Lang): Input language object containing word-to-index and index-to-word mappings.\n",
        "        output_lang (Lang): Output language object containing word-to-index and index-to-word mappings.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Tensor]: A tuple containing the list of decoded words and the decoder attention.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)  # Convert input sentence to tensor\n",
        "\n",
        "        # Encode input sentence\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "        # Decode using the encoder outputs and hidden state\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        # Get the index of the highest probability output token for each timestep\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:  # If end of sentence token, append '<EOS>' and break\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])  # Append the decoded word\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    \"\"\"\n",
        "    Evaluate the encoder-decoder model on random input-output pairs.\n",
        "\n",
        "    Args:\n",
        "        encoder (torch.nn.Module): Encoder model.\n",
        "        decoder (torch.nn.Module): Decoder model.\n",
        "        n (int): Number of pairs to evaluate. Defaults to 10.\n",
        "    \"\"\"\n",
        "    total_correct = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)  # Choose a random pair from the dataset\n",
        "        print('>', pair[0])  # Print the input sequence\n",
        "        print('=', pair[1])  # Print the target output sequence\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)  # Evaluate the pair\n",
        "        output_sentence = ' '.join(output_words)  # Convert the list of output words to a sentence\n",
        "        print('<', output_sentence)  # Print the generated output sequence\n",
        "\n",
        "        # Calculate accuracy\n",
        "        target_words = pair[1].split()\n",
        "        correct = sum(1 for pred, target in zip(output_words, target_words) if pred == target)\n",
        "        total_correct += correct\n",
        "        total_words += len(target_words)\n",
        "\n",
        "        print('Accuracy for this pair:', correct / len(target_words))  # Print accuracy for this pair\n",
        "        print('')  # Print an empty line for clarity\n",
        "\n",
        "    print('Overall accuracy:', total_correct / total_words)  # Print overall accuracy"
      ],
      "metadata": {
        "id": "OunwvG_00QuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 20, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "Xq24snOc0QKV",
        "outputId": "425e075a-4084-4971-e9a7-cca8f5f03c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "3m 30s (- 10m 31s) (5 25%) 1.5247\n",
            "7m 0s (- 7m 0s) (10 50%) 0.6697\n",
            "10m 31s (- 3m 30s) (15 75%) 0.3484\n",
            "14m 2s (- 0m 0s) (20 100%) 0.1955\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar8tEwPo0egm",
        "outputId": "9c9609d9-6022-4bdd-c500-dfa77c2c94b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> vous etes trop lents\n",
            "= you re too slow\n",
            "< you re too polite <EOS>\n",
            "Accuracy for this pair: 0.75\n",
            "\n",
            "> elle est de nouveau elle meme\n",
            "= she is her old self again\n",
            "< she is studying the same age <EOS>\n",
            "Accuracy for this pair: 0.3333333333333333\n",
            "\n",
            "> nous connaissons la reussite\n",
            "= we re successful\n",
            "< we re successful the same problems <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> tu es occupe en ce moment ?\n",
            "= you are busy now aren t you ?\n",
            "< you are busy now aren t you ? <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> elles sont trop grosses\n",
            "= they re too fat\n",
            "< they re too fat <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> j ai peur qu elle ait les oreillons\n",
            "= i m afraid she may have the mumps\n",
            "< i m afraid she may have the mumps <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> j ai une faim de loup\n",
            "= i m very hungry\n",
            "< i m very hungry <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> je me vets\n",
            "= i am getting dressed\n",
            "< i am getting dressed <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "> j ai peur des chiens\n",
            "= i m afraid of dogs\n",
            "< i am afraid of dogs <EOS>\n",
            "Accuracy for this pair: 0.8\n",
            "\n",
            "> elles sont chretiennes\n",
            "= they are christians\n",
            "< they are christians <EOS>\n",
            "Accuracy for this pair: 1.0\n",
            "\n",
            "Overall accuracy: 0.8775510204081632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    \"\"\"\n",
        "    Function to calculate accuracy.\n",
        "    \"\"\"\n",
        "    return np.mean(np.array(predictions) == np.array(targets))\n",
        "\n",
        "def evaluate_accuracy(encoder, decoder, dataloader, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Function to evaluate accuracy on a dataset.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            input_tensor, target_tensor = data\n",
        "\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            _, topi = decoder_outputs.topk(1)\n",
        "            decoded_ids = topi.squeeze()\n",
        "\n",
        "            for idx_tensor, target_tensor in zip(decoded_ids, target_tensor.squeeze()):\n",
        "                for idx in idx_tensor:\n",
        "                    idx = idx.item()  # Convert tensor element to scalar\n",
        "                    if idx == EOS_token:\n",
        "                        predictions.append('<EOS>')\n",
        "                    else:\n",
        "                        predictions.append(output_lang.index2word[idx])\n",
        "\n",
        "\n",
        "                for target_idx in target_tensor:\n",
        "                    target = target_idx.item()  # Convert tensor element to scalar\n",
        "                    if target == EOS_token:\n",
        "                        targets.append('<EOS>')\n",
        "                    else:\n",
        "                        targets.append(output_lang.index2word[target])\n",
        "\n",
        "    return calculate_accuracy(predictions, targets)\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        for idx, target_idx in zip(decoded_ids, target_tensor.squeeze()):\n",
        "            if idx.item() == EOS_token:\n",
        "                predictions.append('<EOS>')\n",
        "            else:\n",
        "                predictions.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "            if target_idx.item() == EOS_token:\n",
        "                targets.append('<EOS>')\n",
        "            else:\n",
        "                targets.append(output_lang.index2word[target_idx.item()])\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = calculate_accuracy(predictions, targets)\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "            print(\"Training Accuracy: %.4f\" % accuracy)\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "# Evaluate training accuracy\n",
        "train_accuracy = evaluate_accuracy(encoder, decoder, train_dataloader, input_lang, output_lang)\n",
        "print(\"Final Training Accuracy with Attention: %.4f\" % train_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eihkpH5M0eVm",
        "outputId": "2bf15244-668c-4fa6-ee80-b8f621c41515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Accuracy with Attention: 0.9768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dz0qrYqC1lH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}